{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e24f2bf8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Dropout, BatchNormalization\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b1a7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the dataset\n",
    "matches = pd.read_csv(\"matches_6_years.csv\", index_col=0)\n",
    "\n",
    "# Convert date column to datetime\n",
    "matches[\"date\"] = pd.to_datetime(matches[\"date\"])\n",
    "\n",
    "# Create target variable: 1 for win, 0 otherwise\n",
    "matches[\"target\"] = (matches[\"result\"] == \"W\").astype(\"int\")\n",
    "\n",
    "# Convert categorical variables to numerical codes\n",
    "matches[\"venue_code\"] = matches[\"venue\"].astype(\"category\").cat.codes\n",
    "matches[\"opp_code\"] = matches[\"opponent\"].astype(\"category\").cat.codes\n",
    "matches[\"hour\"] = matches[\"time\"].str.replace(\":.+\", \"\", regex=True).astype(\"int\")\n",
    "matches[\"day_code\"] = matches[\"date\"].dt.dayofweek\n",
    "\n",
    "# Define predictors and target variable\n",
    "predictors = [\"venue_code\", \"opp_code\", \"hour\", \"day_code\"]\n",
    "target = \"target\"\n",
    "\n",
    "# Split data into train and test sets with stratified sampling\n",
    "train, test = train_test_split(matches, test_size=0.2, stratify=matches[target], random_state=42)\n",
    "\n",
    "# Create MLP model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=len(predictors), activation='relu'))  # Input layer with 64 neurons\n",
    "model.add(Dense(32, activation='relu'))  # Hidden layer with 32 neurons\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer with 1 neuron (binary classification)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train[predictors], train[target], epochs=10, batch_size=32, verbose=0)  # Set verbose to 0 to suppress training output\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test[predictors], test[target], verbose=0)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions_prob = model.predict(test[predictors])\n",
    "predictions = (predictions_prob > 0.5).astype(int)\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "precision = precision_score(test[target], predictions)\n",
    "recall = recall_score(test[target], predictions)\n",
    "f1 = f1_score(test[target], predictions)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bc8483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae84b49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_matches = matches.groupby(\"team\")\n",
    "group = grouped_matches.get_group(\"Manchester City\").sort_values(\"date\")\n",
    "def rolling_averages(group, cols, new_cols):\n",
    "    group = group.sort_values(\"date\")\n",
    "    rolling_stats = group[cols].rolling(3, closed='left').mean()\n",
    "    group[new_cols] = rolling_stats\n",
    "    group = group.dropna(subset=new_cols)\n",
    "    return group\n",
    "\n",
    "cols = [\"gf\", \"ga\", \"sh\", \"sot\", \"dist\", \"fk\", \"pk\", \"pkatt\"]\n",
    "new_cols = [f\"{c}_rolling\" for c in cols]\n",
    "\n",
    "rolling_averages(group, cols, new_cols)\n",
    "matches_rolling = matches.groupby(\"team\").apply(lambda x: rolling_averages(x, cols, new_cols))\n",
    "matches_rolling = matches_rolling.droplevel('team')\n",
    "matches_rolling.index = range(matches_rolling.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63442adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(data, predictors):\n",
    "    train = data[data[\"date\"] < '2022-01-01']\n",
    "    test = data[data[\"date\"] > '2022-01-01']\n",
    "    mlp = MLPClassifier()  # Initialize your MLPClassifier\n",
    "    mlp.fit(train[predictors], train[\"target\"])\n",
    "    preds = mlp.predict(test[predictors])\n",
    "    combined = pd.DataFrame({'actual': test[\"target\"], 'predicted': preds}, index=test.index)\n",
    "    accuracy = accuracy_score(test[\"target\"], preds)\n",
    "    precision = precision_score(test[\"target\"], preds, average='macro')\n",
    "    recall = recall_score(test[\"target\"], preds, average='macro')\n",
    "    f1 = f1_score(test[\"target\"], preds, average='macro')\n",
    "    return combined, accuracy, precision, recall, f1\n",
    "\n",
    "# Assuming you have a DataFrame called `matches_rolling` and a list of predictors called `predictors` and new columns called `new_cols`\n",
    "combined, accuracy, precision, recall, f1 = make_predictions(matches_rolling, predictors + new_cols)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4684ea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "train_scaled = scaler.fit_transform(train[predictors])\n",
    "test_scaled = scaler.transform(test[predictors])\n",
    "\n",
    "# Define MLP classifier\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "parameters = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'max_iter': [200, 500, 1000]\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "grid_search = GridSearchCV(mlp, parameters, cv=5, n_jobs=-1)\n",
    "grid_search.fit(train_scaled, train[\"target\"])\n",
    "\n",
    "# Best parameters found\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "\n",
    "# Train the model with best parameters\n",
    "best_mlp = MLPClassifier(**best_params)\n",
    "best_mlp.fit(train_scaled, train[\"target\"])\n",
    "\n",
    "# Predictions on the test set\n",
    "predictions = best_mlp.predict(test_scaled)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(test[\"target\"], predictions)\n",
    "precision = precision_score(test[\"target\"], predictions)\n",
    "recall = recall_score(test[\"target\"], predictions)\n",
    "f1 = f1_score(test[\"target\"], predictions)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
